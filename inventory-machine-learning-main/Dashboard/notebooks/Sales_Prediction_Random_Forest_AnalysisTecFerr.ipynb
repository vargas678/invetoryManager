{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"border: 2px solid #E57373; border-radius: 10px; padding: 20px; background-color: #FFCDD2;\">\n",
    "    <h1 style=\"font-size: 28px; color: #D32F2F;\">Predicci√≥n Inteligente de Inventarios y Ventas con Aprendizaje Autom√°tico</h1>\n",
    "    <p style=\"font-size: 18px; color: #EF6C00;\">\"Aprovechando el Poder del Aprendizaje Autom√°tico para Optimizar Inventarios y Potenciar la Rentabilidad Empresarial\"</p>\n",
    "    <img src=\"./images/logo.jpg\" alt=\"Imagen de ejemplo\" style=\"border-radius: 5px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.2); max-width: 80%; margin-top: 20px;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\">  1. Introducci√≥n üöÄ</div> </font></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"explain-box\">\n",
    "    Las <b>empresas</b> necesitan comprender los <b>datos de ventas</b>. Nos adentraremos profundamente en estos datos para descubrir <b>conocimientos cruciales</b> con la ayuda del <u>an√°lisis exploratorio de datos (AED)</u>. En este estudio, vamos a examinar estos <b>datos de ventas simples</b>. Nuestra misi√≥n es descubrir <b>conocimientos no revelados</b> que puedan <b>aumentar las ganancias</b> y <b>mejorar la toma de decisiones</b> para las empresas. Analizaremos los datos utilizando <b>t√©cnicas de AED</b> para encontrar <b>informaci√≥n importante</b> que pueda ayudar a las empresas a tener √©xito. Aqu√≠ utilizaremos <u>Pandas</u> para el <b>preprocesamiento y la limpieza de datos</b>, y tambi√©n utilizaremos <u>Matplotlib, Plotly y seaborn</u> para las <b>visualizaciones</b>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La eficiente **gesti√≥n del inventario** es un componente crucial para el √©xito de cualquier empresa. No solo garantiza la **disponibilidad adecuada de productos** para satisfacer la demanda del cliente, sino que tambi√©n **optimiza los costos** y facilita la **toma de decisiones estrat√©gicas basadas en datos**.\n",
    "\n",
    "La **gesti√≥n de bases de datos de inventario** desempe√±a un papel fundamental en este proceso, al facilitar el **seguimiento y control de los productos en stock**, las ventas, los pedidos y las entregas. M√°s que una simple herramienta, una **base de datos bien dise√±ada** se convierte en la columna vertebral de las operaciones comerciales, influyendo en la eficiencia, la rentabilidad y la capacidad de respuesta ante las demandas del mercado.\n",
    "\n",
    "En el mundo empresarial actual, donde la competencia es feroz y las demandas del cliente son cada vez m√°s sofisticadas, la **gesti√≥n tradicional del inventario** ya no es suficiente. Es aqu√≠ donde entra en juego el **an√°lisis impulsado por inteligencia artificial (IA)**. Al aprovechar las **t√©cnicas de aprendizaje autom√°tico**, las empresas pueden analizar grandes vol√∫menes de datos de manera m√°s r√°pida y precisa de lo que ser√≠a posible con m√©todos convencionales.\n",
    "\n",
    "La gesti√≥n de inventario presenta varios desaf√≠os que las empresas deben abordar de manera efectiva, desde la **predicci√≥n de la demanda** hasta la **coordinaci√≥n de la cadena de suministro** y la **gesti√≥n de productos perecederos**. Estos desaf√≠os pueden ser abordados de manera m√°s eficiente con el uso de herramientas de IA que permiten el **an√°lisis de datos a gran escala** y la generaci√≥n de **insights valiosos**.\n",
    "\n",
    "La implementaci√≥n de soluciones de IA puede proporcionar una **ventaja competitiva significativa** al predecir la demanda de los productos, optimizar los niveles de inventario y mejorar la eficiencia operativa en general. Al combinar **datos hist√≥ricos** con **algoritmos avanzados de aprendizaje autom√°tico**, las empresas pueden tomar **decisiones m√°s informadas y proactivas**, reduciendo los costos y maximizando los beneficios.\n",
    "\n",
    "Para implementar una gesti√≥n eficaz del inventario, es crucial contar con una **base de datos del sistema de gesti√≥n de inventario robusta y bien dise√±ada**. Esta herramienta no solo permite el seguimiento de los niveles de existencias, log√≠stica y las transacciones, sino que tambi√©n proporciona informaci√≥n valiosa para la toma de decisiones estrat√©gicas. Al analizar datos en tiempo real, las empresas pueden identificar tendencias, anticipar cambios en la demanda y ajustar su inventario de manera proactiva, optimizando sus procesos operativos y mejorando su rentabilidad y competitividad en el mercado.\n",
    "\n",
    "Este proyecto busca dise√±ar una **base de datos robusta y escalable** que sirva como cimiento para una **aplicaci√≥n de gesti√≥n de inventario y an√°lisis predictivo de ventas**. Al integrar capacidades de IA en el proceso de gesti√≥n de inventario, las empresas pueden posicionarse mejor para enfrentar los desaf√≠os del mercado actual y aprovechar nuevas oportunidades de crecimiento y expansi√≥n.\n",
    "\n",
    "## Descripci√≥n de las Columnas del DataFrame `df_inventory`\n",
    "\n",
    "<style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        border: 2px solid #008CBA;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "\n",
    "    th, td {\n",
    "        border: 1px solid #008CBA;\n",
    "        padding: 10px;\n",
    "        text-align: left;\n",
    "    }\n",
    "\n",
    "    th {\n",
    "        background-color: #008CBA;\n",
    "        color: white;\n",
    "    }\n",
    "\n",
    "    h2 {\n",
    "        color: #008CBA;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Variable</th>\n",
    "        <th>Descripci√≥n</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MES</td>\n",
    "        <td>N√∫mero del mes correspondiente al registro (1 a 12).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_ALMACENADOS</td>\n",
    "        <td>Cantidad de productos almacenados en el inventario durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_MARKETING</td>\n",
    "        <td>Monto de dinero gastado en marketing durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_ALMACENAMIENTO</td>\n",
    "        <td>Monto de dinero gastado en almacenamiento de productos durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DEMANDA_DEL_PRODUCTO</td>\n",
    "        <td>Nivel de demanda del producto en el mercado durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>FESTIVIDAD</td>\n",
    "        <td>Indicador binario que se√±ala si hubo una festividad durante el mes (0: No, 1: S√≠).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRECIO_DE_VENTA</td>\n",
    "        <td>Precio de venta del producto durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_VENDIDOS</td>\n",
    "        <td>Cantidad de productos vendidos durante el mes.</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Librerias</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTT5A7KHMM1EFWTBFPPY",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Lectura del conjunto de datos</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTA5YTV9XFN0BQT07TA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel con los datos\n",
    "df_inventory = pd.read_excel(\"../Data/Melsol-test.xlsx\")\n",
    "\n",
    "# Mostrar las primeras 5 filas del DataFrame para verificar los datos\n",
    "df_inventory.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTBS6TZVF9DRYBXHNH2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Acerca del Conjunto de Datos</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTCH4SVMS534MN30G23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el n√∫mero de filas y columnas\n",
    "num_filas, num_columnas = df_inventory.shape\n",
    "print(f\"N√∫mero de filas: {num_filas}\")\n",
    "print(f\"N√∫mero de columnas: {num_columnas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTCTW7Q8TXFYYXTVNMR",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos de cada columna\n",
    "print(df_inventory.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        border: 2px solid #008CBA;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "\n",
    "    th, td {\n",
    "        border: 1px solid #008CBA;\n",
    "        padding: 10px;\n",
    "        text-align: left;\n",
    "    }\n",
    "\n",
    "    th {\n",
    "        background-color: #008CBA;\n",
    "        color: white;\n",
    "    }\n",
    "\n",
    "    h2 {\n",
    "        color: #008CBA;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "#### <span style=\"color:#008CBA;\">Descripci√≥n de las Columnas del DataFrame `df_inventory`:</span>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Variable</th>\n",
    "        <th>Descripci√≥n</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MES</td>\n",
    "        <td>N√∫mero del mes correspondiente al registro (1 a 12).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_ALMACENADOS</td>\n",
    "        <td>Cantidad de productos almacenados en el inventario durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_MARKETING</td>\n",
    "        <td>Monto de dinero gastado en marketing durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_ALMACENAMIENTO</td>\n",
    "        <td>Monto de dinero gastado en almacenamiento de productos durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DEMANDA_DEL_PRODUCTO</td>\n",
    "        <td>Nivel de demanda del producto en el mercado durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>FESTIVIDAD</td>\n",
    "        <td>Indicador binario que se√±ala si hubo una festividad durante el mes (0: No, 1: S√≠).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRECIO_DE_VENTA</td>\n",
    "        <td>Precio de venta del producto durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_VENDIDOS</td>\n",
    "        <td>Cantidad de productos vendidos durante el mes.</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTCGFGJCZ2SDG3EMB90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estad√≠stico de las variables numericas\n",
    "df_inventory.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA (Analisis Exploratorio de datos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTDQ7DWP9E448N16CJS",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTEY8ZKFVPAE3ZW5W1R",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualizaci√≥n de la distribuci√≥n de variables\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, column in enumerate(df_inventory.columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(df_inventory[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VERIFICAR DATOS ATIPICOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTFBT5GR053H0V4NEQN",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Seleccionar las columnas num√©ricas\n",
    "numeric_columns = df_inventory.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Crear gr√°ficos de caja para identificar valores at√≠picos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_inventory[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "* Columna PRODUCTOS ALMACENADOS\n",
    "* Columna DEMNADA DEL PRODUCTO\n",
    "* Columna PRODUCTOS VENDIDOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTFQK29MJQY31YY5G99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(column, cap_value=None):\n",
    "    # Calcula el rango intercuart√≠lico (IQR)\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define los l√≠mites superior e inferior para identificar los valores at√≠picos\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Acotar los valores at√≠picos\n",
    "    if cap_value is not None:\n",
    "        column = column.clip(lower=lower_limit, upper=cap_value)\n",
    "    else:\n",
    "        column = column.clip(lower=lower_limit, upper=upper_limit)\n",
    "\n",
    "    return column\n",
    "\n",
    "\n",
    "# Aplicar la funci√≥n a las columnas con valores at√≠picos\n",
    "df_inventory['PRODUCTOS ALMACENADOS'] = handle_outliers(df_inventory['PRODUCTOS ALMACENADOS'])\n",
    "df_inventory['DEMANDA DEL PRODUCTO'] = handle_outliers(df_inventory['DEMANDA DEL PRODUCTO'])\n",
    "df_inventory['PRODUCTOS VENDIDOS'] = handle_outliers(df_inventory['PRODUCTOS VENDIDOS'])\n",
    "df_inventory['PRECIO DE VENTA'] = handle_outliers(df_inventory['PRECIO DE VENTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTF5ARM27GE9MN6HYR9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Seleccionar las columnas num√©ricas\n",
    "numeric_columns = df_inventory.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Crear gr√°ficos de caja para identificar valores at√≠picos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_inventory[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTGS6HFN7KXBACHGKBY",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la matriz de correlaci√≥n\n",
    "correlation_matrix = df_inventory.corr()\n",
    "\n",
    "# Crear una m√°scara para la parte triangular inferior\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Crear la figura y el eje (axis)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crear el mapa de calor con la matriz de correlaci√≥n\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "\n",
    "# Configurar el t√≠tulo\n",
    "plt.title('Correlation Matrix - Upper Triangle Only')\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTGJ1BJ31B4N8QV4RPD",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES** \n",
    "*CORRELACION FUERTE POSITIVA*\n",
    "* PRODUCTOS ALMACENADOS y DEMANDA DEL PRODUCTO: 0.851178\t\n",
    "* PRODUCTOS ALMACENADOS y PRODUCTOS VENDIDOS: 0.83\n",
    "* DEMANDA DEL PRODUCTO y PRODUCTOS VENDIDOS: 0.978426\n",
    "* Correlaci√≥n Fuerte Negativa:\n",
    "\n",
    "*CORRELACION FUERTE NEGATIVA*\n",
    "\n",
    "* FESTIVIDAD y PRODUCTOS VENDIDOS: -0.237186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTGFJRBPCB8AXDNPRC2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionar solo la columna de correlaciones con \"PRODUCTOS VENDIDOS\"\n",
    "correlations_with_target = correlation_matrix['PRODUCTOS VENDIDOS'].drop('PRODUCTOS VENDIDOS')\n",
    "\n",
    "# Crear un gr√°fico de barras para visualizar las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations_with_target.sort_values().plot(kind='barh', color='skyblue')\n",
    "plt.title('Correlaci√≥n con \"PRODUCTOS VENDIDOS\"')\n",
    "plt.xlabel('Correlaci√≥n')\n",
    "plt.ylabel('Variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREPROCESAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTH94105Y3AEPWG4E8F",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el n√∫mero de valores √∫nicos de cada columna\n",
    "for column in df_inventory.columns:\n",
    "    num_unique_values = df_inventory[column].nunique()\n",
    "    print(f'Columna: {column}, N√∫mero de Valores √önicos: {num_unique_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTHWMT2ZTTDQEJ1XNDJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analizar_y_eliminar_ruido(df):\n",
    "    \"\"\"\n",
    "    Analiza el n√∫mero de valores √∫nicos en cada columna y decide si eliminar la columna si la cantidad de valores √∫nicos es igual a 1.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame de pandas\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame modificado sin las columnas identificadas como ruido.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar una lista para almacenar las columnas a eliminar\n",
    "    columnas_a_eliminar = []\n",
    "\n",
    "    # Iterar sobre cada columna del DataFrame\n",
    "    for columna in df.columns:\n",
    "        # Verificar si la cantidad de valores √∫nicos es igual a 1\n",
    "        if df[columna].nunique() == 1:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "            print(f'Columna \"{columna}\" tiene un solo valor √∫nico. Se considera ruido.')\n",
    "\n",
    "    # Eliminar las columnas identificadas como ruido\n",
    "    df_sin_ruido = df.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "    print(f'\\nColumnas eliminadas: {columnas_a_eliminar}')\n",
    "\n",
    "    return df_sin_ruido\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "df_sin_ruido = analizar_y_eliminar_ruido(df_inventory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTHF8FG1VPBYNYMJ0X7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTJ7PC8ZS5PW2AG2R3G",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTJPG63AN24X5VFC3VM",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTJM41KY48PJG6GVEVX",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Seleccionar solo las columnas num√©ricas\n",
    "columnas_numericas = df_sin_ruido.columns\n",
    "\n",
    "# Inicializar el objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar y estandarizar los datos\n",
    "df_sin_ruido_norm_est = scaler.fit_transform(df_sin_ruido[columnas_numericas])\n",
    "\n",
    "# Crear un nuevo DataFrame con los datos normalizados y estandarizados\n",
    "df_sin_ruido_norm_est = pd.DataFrame(df_sin_ruido_norm_est, columns=columnas_numericas)\n",
    "\n",
    "# Mostrar las estad√≠sticas descriptivas del nuevo DataFrame\n",
    "print(df_sin_ruido_norm_est.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTKAB74NS74XTE9F3PE",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido_norm_est.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTKK163B28Q9V8FT79Z",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las caracter√≠sticas (X) y la variable objetivo (y)\n",
    "X = df_sin_ruido_norm_est.drop('PRODUCTOS VENDIDOS', axis=1)\n",
    "y = df_sin_ruido_norm_est['PRODUCTOS VENDIDOS']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Imprimir las formas de los conjuntos resultantes\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTKN40TQK2KMQQ2ZGQ3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Crear el modelo de Random Forest Regression\n",
    "bosque = RandomForestRegressor(n_estimators=100,\n",
    "                               criterion=\"squared_error\",\n",
    "                               max_features=\"sqrt\",\n",
    "                               bootstrap=True,\n",
    "                               oob_score=True,\n",
    "                               random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "bosque.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "nuevos_datos = [[1, 10, 0.4, 5.0, 1]]  # Ajusta estos valores seg√∫n tus datos\n",
    "prediccion = bosque.predict(nuevos_datos)\n",
    "print(\"Predicci√≥n:\", prediccion)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "predicciones_test = bosque.predict(X_test.values)\n",
    "mse = mean_squared_error(y_test.values, predicciones_test)\n",
    "print(\"Error cuadr√°tico medio en el conjunto de prueba:\", mse)\n",
    "\n",
    "# Imprimir la puntuaci√≥n R^2 en el conjunto de entrenamiento\n",
    "print(\"Puntuaci√≥n R^2 en el conjunto de entrenamiento:\", bosque.score(X_train.values, y_train.values))\n",
    "\n",
    "# Imprimir la puntuaci√≥n R^2 en el conjunto de prueba\n",
    "print(\"Puntuaci√≥n R^2 en el conjunto de prueba:\", bosque.score(X_test.values, y_test.values))\n",
    "\n",
    "# Imprimir la puntuaci√≥n \"out-of-bag\" (OOB)\n",
    "print(\"Puntuaci√≥n OOB:\", bosque.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTKMGQFDCW20FRBRJYW",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "# Crear el modelo de Random Forest Regression\n",
    "bosque = RandomForestRegressor(n_estimators=100,\n",
    "                               criterion=\"squared_error\",  # Utilizar \"squared_error\" en lugar de \"mse\"\n",
    "                               max_features=\"sqrt\",\n",
    "                               bootstrap=True,\n",
    "                               oob_score=True,\n",
    "                               random_state=42)\n",
    "\n",
    "# Definir la m√©trica a utilizar (en este caso, negativo del Error Cuadr√°tico Medio para que sea coherente con la validaci√≥n cruzada)\n",
    "metrica = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Realizar validaci√≥n cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # Puedes ajustar el n√∫mero de divisiones (folds)\n",
    "resultados_cross_val = cross_val_score(bosque, X.values, y.values, cv=kf, scoring=metrica)\n",
    "\n",
    "# Imprimir los resultados de la validaci√≥n cruzada\n",
    "print(\"Resultados de la validaci√≥n cruzada:\")\n",
    "print(\"MSE por fold:\", resultados_cross_val)\n",
    "print(\"Promedio MSE:\", resultados_cross_val.mean())\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de datos\n",
    "bosque.fit(X.values, y.values)\n",
    "\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "nuevos_datos = X_test  # Usar X_test en lugar de una instancia individual\n",
    "predicciones = bosque.predict(nuevos_datos)\n",
    "print(\"Predicciones:\", predicciones)\n",
    "\n",
    "# Calcular las m√©tricas de evaluaci√≥n\n",
    "mae_rf = mean_absolute_error(y_test, predicciones)\n",
    "mse_rf = mean_squared_error(y_test, predicciones)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, predicciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTKWV1RR0JFNSKKH2GJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Suponiendo que bosque es tu modelo entrenado\n",
    "for i, arbol in enumerate(bosque.estimators_[:3]):  # Limitar a los primeros tres √°rboles\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    tree.plot_tree(arbol, feature_names=X.columns.tolist(), filled=True, rounded=True)\n",
    "    plt.title(f\"√Årbol {i + 1}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTM432JYYX2YY8P1FCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = bosque.predict(X_test)\n",
    "# Gr√°fico de dispersi√≥n de datos predichos vs. datos reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Predicciones')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--',\n",
    "         label='L√≠nea de Regresi√≥n Ideal')\n",
    "plt.title('Gr√°fico de Dispersi√≥n: Predicciones vs. Datos Reales')\n",
    "plt.xlabel('Datos Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTN6FEBCYQVGY0M99SF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de entrenamiento\n",
    "y_train_pred = bosque.predict(X_train)\n",
    "\n",
    "# Gr√°fico de dispersi√≥n de datos predichos vs. datos reales (entrenamiento)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_train_pred, color='blue', label='Predicciones')\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--',\n",
    "         label='L√≠nea de Regresi√≥n Ideal')\n",
    "plt.title('Gr√°fico de Dispersi√≥n: Predicciones vs. Datos Reales (Conjunto de Entrenamiento)')\n",
    "plt.xlabel('Datos Reales (Entrenamiento)')\n",
    "plt.ylabel('Predicciones (Entrenamiento)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTNZ4YMGK3C4TKWAQ4D",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test):\n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    predicciones = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular las m√©tricas de evaluaci√≥n\n",
    "    mae = metrics.mean_absolute_error(y_test, predicciones)\n",
    "    mse = metrics.mean_squared_error(y_test, predicciones)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_test, predicciones)\n",
    "\n",
    "    return mae, mse, rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTNXGYGRDXFA5FYW2N0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo_lr = LinearRegression()\n",
    "mae_lr, mse_lr, rmse_lr, r2_lr = evaluar_modelo(modelo_lr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTNATDJ4ZQ5NH12H2FT",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "modelo_lasso = Lasso()\n",
    "mae_lasso, mse_lasso, rmse_lasso, r2_lasso = evaluar_modelo(modelo_lasso, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTP3A5YXDMQKW3NXPHG",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "modelo_svr = SVR()\n",
    "mae_svr, mse_svr, rmse_svr, r2_svr = evaluar_modelo(modelo_svr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTPTX0PDX9N90D4XHPY",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "modelo_gb = GradientBoostingRegressor(random_state=42)\n",
    "mae_gb, mse_gb, rmse_gb, r2_gb = evaluar_modelo(modelo_gb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTP2K481G56Y7378746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "modelo_svm = SVR()\n",
    "mae_svm, mse_svm, rmse_svm, r2_svm = evaluar_modelo(modelo_svm, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTP2MPXN32VFH2KDHWF",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "modelo_knn = KNeighborsRegressor()\n",
    "mae_knn, mse_knn, rmse_knn, r2_knn = evaluar_modelo(modelo_knn, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTP27C8RZ7Y3DT8F171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "modelo_xgb = XGBRegressor(random_state=42)\n",
    "mae_xgb, mse_xgb, rmse_xgb, r2_xgb = evaluar_modelo(modelo_xgb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTQABPSMRCCJ42H8V50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression ya fue implementado en la regresi√≥n lineal\n",
    "mae_mlr, mse_mlr, rmse_mlr, r2_mlr = mae_lr, mse_lr, rmse_lr, r2_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTQQD011KZE6MN3N52X",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "modelo_ridge = Ridge()\n",
    "mae_ridge, mse_ridge, rmse_ridge, r2_ridge = evaluar_modelo(modelo_ridge, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTQA53K9GDPTFRNV1DT",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "modelo_enr = ElasticNet()\n",
    "mae_enr, mse_enr, rmse_enr, r2_enr = evaluar_modelo(modelo_enr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J002NTTQHPP0JB3YYMCB8V8V",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "modelo_pnr = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "mae_pnr, mse_pnr, rmse_pnr, r2_pnr = evaluar_modelo(modelo_pnr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las m√©tricas de los modelos\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Regresi√≥n Lineal', 'Lasso Regression', 'Support Vector Regression', 'Gradient Boosting', 'SVM', 'KNN',\n",
    "               'XGBoost', 'Ridge Linear Regression', 'Elastic-Net Regression', 'Polynomial Regression'],\n",
    "    'MAE': [mae_lr, mae_lasso, mae_svr, mae_gb, mae_svm, mae_knn, mae_xgb, mae_ridge, mae_enr, mae_pnr],\n",
    "    'MSE': [mse_lr, mse_lasso, mse_svr, mse_gb, mse_svm, mse_knn, mse_xgb, mse_ridge, mse_enr, mse_pnr],\n",
    "    'RMSE': [rmse_lr, rmse_lasso, rmse_svr, rmse_gb, rmse_svm, rmse_knn, rmse_xgb, rmse_ridge, rmse_enr, rmse_pnr],\n",
    "    'R¬≤': [r2_lr, r2_lasso, r2_svr, r2_gb, r2_svm, r2_knn, r2_xgb, r2_ridge, r2_enr, r2_pnr],\n",
    "})\n",
    "\n",
    "# Agregar las m√©tricas del modelo de Random Forest a la tabla de resultados\n",
    "resultados.loc[len(resultados)] = ['Random Forest Regression', mae_rf, mse_rf, rmse_rf, r2_rf]\n",
    "\n",
    "# Mostrar el DataFrame con las m√©tricas\n",
    "print(resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los par√°metros para la b√∫squeda de hiperpar√°metros\n",
    "parametros = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "modelo_xgb_grid = XGBRegressor(random_state=42)\n",
    "busqueda = GridSearchCV(estimator=modelo_xgb_grid, param_grid=parametros, cv=3, scoring='neg_mean_squared_error',\n",
    "                        verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entrenar el modelo con la b√∫squeda de hiperpar√°metros\n",
    "busqueda.fit(X_train, y_train)\n",
    "mejores_params = busqueda.best_params_\n",
    "\n",
    "# Evaluar el mejor modelo encontrado\n",
    "mejor_modelo_xgb = busqueda.best_estimator_\n",
    "mae_xgb_ht, mse_xgb_ht, rmse_xgb_ht, r2_xgb_ht = evaluar_modelo(mejor_modelo_xgb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# A√±adir el modelo hypertuned a la tabla de resultados\n",
    "resultados.loc[len(resultados)] = ['Hypertuned XGBoost', mae_xgb_ht, mse_xgb_ht, rmse_xgb_ht, r2_xgb_ht]\n",
    "\n",
    "# Mostrar el DataFrame actualizado con las m√©tricas\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; border: 1px solid #ddd; padding: 15px; border-radius: 10px;color: black\">\n",
    "    <p style=\"font-size: 18px; color: #2E86C1;\">An√°lisis de los Resultados de los Modelos</p>\n",
    "    <p>El an√°lisis de los resultados de los modelos proporciona una visi√≥n completa del rendimiento de cada modelo:</p>    \n",
    "    <ul>\n",
    "        <li>Mejor Modelo:</li>\n",
    "        <ul>\n",
    "            <li>Random Forest Regression: Este modelo tiene el rendimiento m√°s s√≥lido con un MAE bajo de aproximadamente 0.19, un MSE de alrededor de 0.06, un RMSE de aproximadamente 0.24 y un R¬≤ de alrededor de 0.74. Indica un bajo error y una buena capacidad para explicar la variabilidad de los datos.</li>\n",
    "        </ul>\n",
    "        <li>Segundos Mejores Modelos:</li>\n",
    "        <ul>\n",
    "            <li>Regresi√≥n Lineal: Aunque ligeramente superado por Random Forest, muestra un rendimiento s√≥lido con un MAE de aproximadamente 0.21, un MSE de alrededor de 0.07, un RMSE de aproximadamente 0.27 y un R¬≤ de alrededor de 0.68.</li>\n",
    "            <li>Polynomial Regression: Con un MAE de aproximadamente 0.25, un MSE de alrededor de 0.07, un RMSE de aproximadamente 0.26 y un R¬≤ de alrededor de 0.69, es otra opci√≥n s√≥lida.</li>\n",
    "        </ul>\n",
    "        <li>Peores Modelos:</li>\n",
    "        <ul>\n",
    "            <li>XGBoost: Muestra un rendimiento deficiente con un MAE de aproximadamente 0.76, un MSE de alrededor de 1.27, un RMSE de aproximadamente 1.13 y un R¬≤ negativo de alrededor de -4.79.</li>\n",
    "            <li>Hypertuned XGBoost: Similar al XGBoost regular, muestra un rendimiento muy pobre con un MAE de aproximadamente 0.75, un MSE de alrededor de 1.32, un RMSE de aproximadamente 1.15 y un R¬≤ negativo de alrededor de -5.03.</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    <p>En resumen, Random Forest Regression destaca como el mejor modelo, seguido de cerca por la Regresi√≥n Lineal y Polynomial Regression. XGBoost y su versi√≥n Hypertuned XGBoost muestran un rendimiento deficiente y deben ser evitados.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"border: 2px solid #E57373; border-radius: 10px; padding: 20px; background-color: #FFCDD2;\">\n",
    "    <h1 style=\"font-size: 28px; color: #D32F2F;\">Predicci√≥n Inteligente de Inventarios y Ventas con Aprendizaje Autom√°tico</h1>\n",
    "    <p style=\"font-size: 18px; color: #EF6C00;\">\"Aprovechando el Poder del Aprendizaje Autom√°tico para Optimizar Inventarios y Potenciar la Rentabilidad Empresarial\"</p>\n",
    "    <img src=\"./images/logo.jpg\" alt=\"Imagen de ejemplo\" style=\"border-radius: 5px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.2); max-width: 80%; margin-top: 20px;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Librerias</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDT02M58WZSNBVTX3KJN",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Lectura del conjunto de datos</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDTXGAG48M77FRX9VD4J",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel con los datos\n",
    "df_inventory = pd.read_excel(\"../Data/Melsol-test.xlsx\")\n",
    "\n",
    "# Mostrar las primeras 5 filas del DataFrame para verificar los datos\n",
    "df_inventory.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDTXNR9WH8T1CGQQ3E73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a><font size=\"6\"><div style=\"border-radius:5px;color:#2F4F4F;background-color:#BFBF00;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Acerca del Conjunto de Datos</div></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDTYJZNYE8YTCC5AD43V",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el n√∫mero de filas y columnas\n",
    "num_filas, num_columnas = df_inventory.shape\n",
    "print(f\"N√∫mero de filas: {num_filas}\")\n",
    "print(f\"N√∫mero de columnas: {num_columnas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDTY0N31SWSHCF07N94Y",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos de cada columna\n",
    "print(df_inventory.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        border: 2px solid #008CBA;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "\n",
    "    th, td {\n",
    "        border: 1px solid #008CBA;\n",
    "        padding: 10px;\n",
    "        text-align: left;\n",
    "    }\n",
    "\n",
    "    th {\n",
    "        background-color: #008CBA;\n",
    "        color: white;\n",
    "    }\n",
    "\n",
    "    h2 {\n",
    "        color: #008CBA;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "#### <span style=\"color:#008CBA;\">Descripci√≥n de las Columnas del DataFrame `df_inventory`:</span>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Variable</th>\n",
    "        <th>Descripci√≥n</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MES</td>\n",
    "        <td>N√∫mero del mes correspondiente al registro (1 a 12).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_ALMACENADOS</td>\n",
    "        <td>Cantidad de productos almacenados en el inventario durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_MARKETING</td>\n",
    "        <td>Monto de dinero gastado en marketing durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GASTO_DE_ALMACENAMIENTO</td>\n",
    "        <td>Monto de dinero gastado en almacenamiento de productos durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DEMANDA_DEL_PRODUCTO</td>\n",
    "        <td>Nivel de demanda del producto en el mercado durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>FESTIVIDAD</td>\n",
    "        <td>Indicador binario que se√±ala si hubo una festividad durante el mes (0: No, 1: S√≠).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRECIO_DE_VENTA</td>\n",
    "        <td>Precio de venta del producto durante el mes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PRODUCTOS_VENDIDOS</td>\n",
    "        <td>Cantidad de productos vendidos durante el mes.</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV0YWERAWJM5HC4MMKW",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estad√≠stico de las variables numericas\n",
    "df_inventory.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA (Analisis Exploratorio de datos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV040ZYM68QRT4K8MXN",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV14270P7ZQ6P0K5WJA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Inicializar la aplicaci√≥n\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Excluir la columna 'MES'\n",
    "excluded_columns = [\"MES\"]\n",
    "columns_for_dropdown = [\n",
    "    col for col in df_inventory.columns if col not in excluded_columns\n",
    "]\n",
    "\n",
    "# Dise√±o de la aplicaci√≥n\n",
    "app.layout = html.Div(\n",
    "    style={\"textAlign\": \"center\", \"padding\": \"20px\"},\n",
    "    children=[\n",
    "        html.H1(\"Gr√°fico de Correlaci√≥n con MES\", style={\"color\": \"#2E86C1\"}),\n",
    "        html.Hr(),\n",
    "        dcc.Dropdown(\n",
    "            id=\"dropdown-column\",\n",
    "            options=[{\"label\": col, \"value\": col} for col in columns_for_dropdown],\n",
    "            value=\"PRODUCTOS_ALMACENADOS\",\n",
    "            multi=False,\n",
    "            style={\"width\": \"50%\", \"margin\": \"auto\"},\n",
    "        ),\n",
    "        dcc.Graph(id=\"correlation-plot\", style={\"margin-top\": \"20px\"}),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Definir la funci√≥n de devoluci√≥n de llamada\n",
    "@callback(\n",
    "    Output(component_id=\"correlation-plot\", component_property=\"figure\"),\n",
    "    Input(component_id=\"dropdown-column\", component_property=\"value\"),\n",
    ")\n",
    "def update_correlation_plot(selected_column):\n",
    "    corr_data = df_inventory[[\"MES\", selected_column]]\n",
    "    fig = px.scatter(\n",
    "        corr_data,\n",
    "        x=\"MES\",\n",
    "        y=selected_column,\n",
    "        title=f\"Correlaci√≥n entre MES y {selected_column}\",\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"#F9F9F9\",  # Color de fondo del gr√°fico\n",
    "        paper_bgcolor=\"#F9F9F9\",  # Color de fondo del √°rea de trazado\n",
    "        font_color=\"#333333\",  # Color de fuente\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Ejecutar la aplicaci√≥n\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV2B2ZAW93GQNMXH60B",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualizaci√≥n de la distribuci√≥n de variables\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, column in enumerate(df_inventory.columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(df_inventory[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VERIFICAR DATOS ATIPICOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV3ZW9EP136X2RMF388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Seleccionar las columnas num√©ricas\n",
    "numeric_columns = df_inventory.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Crear gr√°ficos de caja para identificar valores at√≠picos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_inventory[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "* Columna PRODUCTOS ALMACENADOS\n",
    "* Columna DEMNADA DEL PRODUCTO\n",
    "* Columna PRODUCTOS VENDIDOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV3G811HPRZP0R2KPSP",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(column, cap_value=None):\n",
    "    # Calcula el rango intercuart√≠lico (IQR)\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define los l√≠mites superior e inferior para identificar los valores at√≠picos\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Acotar los valores at√≠picos\n",
    "    if cap_value is not None:\n",
    "        column = column.clip(lower=lower_limit, upper=cap_value)\n",
    "    else:\n",
    "        column = column.clip(lower=lower_limit, upper=upper_limit)\n",
    "    \n",
    "    return column\n",
    "\n",
    "# Aplicar la funci√≥n a las columnas con valores at√≠picos\n",
    "df_inventory['PRODUCTOS ALMACENADOS'] = handle_outliers(df_inventory['PRODUCTOS ALMACENADOS'])\n",
    "df_inventory['DEMANDA DEL PRODUCTO'] = handle_outliers(df_inventory['DEMANDA DEL PRODUCTO'])\n",
    "df_inventory['PRODUCTOS VENDIDOS'] = handle_outliers(df_inventory['PRODUCTOS VENDIDOS'])\n",
    "df_inventory['PRECIO DE VENTA'] = handle_outliers(df_inventory['PRECIO DE VENTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV46YZ1SMGRZK5PQW12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Seleccionar las columnas num√©ricas\n",
    "numeric_columns = df_inventory.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Crear gr√°ficos de caja para identificar valores at√≠picos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_inventory[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV4QQQC8ZTWGSMFYTMF",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la matriz de correlaci√≥n\n",
    "correlation_matrix = df_inventory.corr()\n",
    "\n",
    "# Crear una m√°scara para la parte triangular inferior\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Configurar el estilo de los gr√°ficos\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Crear la figura y el eje (axis)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crear el mapa de calor con la matriz de correlaci√≥n\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "\n",
    "# Configurar el t√≠tulo\n",
    "plt.title('Correlation Matrix - Upper Triangle Only')\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV50TQDMDSYJ6C7VREK",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES** \n",
    "*CORRELACION FUERTE POSITIVA*\n",
    "* PRODUCTOS ALMACENADOS y DEMANDA DEL PRODUCTO: 0.851178\t\n",
    "* PRODUCTOS ALMACENADOS y PRODUCTOS VENDIDOS: 0.83\n",
    "* DEMANDA DEL PRODUCTO y PRODUCTOS VENDIDOS: 0.978426\n",
    "* Correlaci√≥n Fuerte Negativa:\n",
    "\n",
    "*CORRELACION FUERTE NEGATIVA*\n",
    "\n",
    "* FESTIVIDAD y PRODUCTOS VENDIDOS: -0.237186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV65150FFQ16BQY7QHS",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionar solo la columna de correlaciones con \"PRODUCTOS VENDIDOS\"\n",
    "correlations_with_target = correlation_matrix['PRODUCTOS VENDIDOS'].drop('PRODUCTOS VENDIDOS')\n",
    "\n",
    "# Crear un gr√°fico de barras para visualizar las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations_with_target.sort_values().plot(kind='barh', color='skyblue')\n",
    "plt.title('Correlaci√≥n con \"PRODUCTOS VENDIDOS\"')\n",
    "plt.xlabel('Correlaci√≥n')\n",
    "plt.ylabel('Variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREPROCESAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV73TP6F508ETX10QF0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el n√∫mero de valores √∫nicos de cada columna\n",
    "for column in df_inventory.columns:\n",
    "    num_unique_values = df_inventory[column].nunique()\n",
    "    print(f'Columna: {column}, N√∫mero de Valores √önicos: {num_unique_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV7W3RS4ZSVAK0SXA0J",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analizar_y_eliminar_ruido(df):\n",
    "    \"\"\"\n",
    "    Analiza el n√∫mero de valores √∫nicos en cada columna y decide si eliminar la columna si la cantidad de valores √∫nicos es igual a 1.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame de pandas\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame modificado sin las columnas identificadas como ruido.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar una lista para almacenar las columnas a eliminar\n",
    "    columnas_a_eliminar = []\n",
    "\n",
    "    # Iterar sobre cada columna del DataFrame\n",
    "    for columna in df.columns:\n",
    "        # Verificar si la cantidad de valores √∫nicos es igual a 1\n",
    "        if df[columna].nunique() == 1:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "            print(f'Columna \"{columna}\" tiene un solo valor √∫nico. Se considera ruido.')\n",
    "\n",
    "    # Eliminar las columnas identificadas como ruido\n",
    "    df_sin_ruido = df.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "    print(f'\\nColumnas eliminadas: {columnas_a_eliminar}')\n",
    "\n",
    "    return df_sin_ruido\n",
    "\n",
    "# Ejemplo de uso\n",
    "df_sin_ruido = analizar_y_eliminar_ruido(df_inventory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV8V615NWGZPT9PC1CN",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV95ACGKCWPEZ0S989C",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDV9HCP4VJWS5PVP8ZWA",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVAS09X9NE8N958MYGG",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Seleccionar solo las columnas num√©ricas\n",
    "columnas_numericas = df_sin_ruido.columns\n",
    "\n",
    "# Inicializar el objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar y estandarizar los datos\n",
    "df_sin_ruido_norm_est = scaler.fit_transform(df_sin_ruido[columnas_numericas])\n",
    "\n",
    "# Crear un nuevo DataFrame con los datos normalizados y estandarizados\n",
    "df_sin_ruido_norm_est = pd.DataFrame(df_sin_ruido_norm_est, columns=columnas_numericas)\n",
    "\n",
    "# Mostrar las estad√≠sticas descriptivas del nuevo DataFrame\n",
    "print(df_sin_ruido_norm_est.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVBRSQR4YW0TCC2B1YC",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ruido_norm_est.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVBJF2GWTMWT85RG1DR",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las caracter√≠sticas (X) y la variable objetivo (y)\n",
    "X = df_sin_ruido_norm_est.drop('PRODUCTOS VENDIDOS', axis=1)\n",
    "y = df_sin_ruido_norm_est['PRODUCTOS VENDIDOS']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Imprimir las formas de los conjuntos resultantes\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVC5XKF7K0CEYYJ3CT6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Crear el modelo de Random Forest Regression\n",
    "bosque = RandomForestRegressor(n_estimators=100,\n",
    "                                criterion=\"squared_error\",\n",
    "                                max_features=\"sqrt\",\n",
    "                                bootstrap=True,\n",
    "                                oob_score=True,\n",
    "                                random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "bosque.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "nuevos_datos = [[1, 10, 0.4, 5.0, 1]]  # Ajusta estos valores seg√∫n tus datos\n",
    "prediccion = bosque.predict(nuevos_datos)\n",
    "print(\"Predicci√≥n:\", prediccion)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "predicciones_test = bosque.predict(X_test.values)\n",
    "mse = mean_squared_error(y_test.values, predicciones_test)\n",
    "print(\"Error cuadr√°tico medio en el conjunto de prueba:\", mse)\n",
    "\n",
    "# Imprimir la puntuaci√≥n R^2 en el conjunto de entrenamiento\n",
    "print(\"Puntuaci√≥n R^2 en el conjunto de entrenamiento:\", bosque.score(X_train.values, y_train.values))\n",
    "\n",
    "# Imprimir la puntuaci√≥n R^2 en el conjunto de prueba\n",
    "print(\"Puntuaci√≥n R^2 en el conjunto de prueba:\", bosque.score(X_test.values, y_test.values))\n",
    "\n",
    "# Imprimir la puntuaci√≥n \"out-of-bag\" (OOB)\n",
    "print(\"Puntuaci√≥n OOB:\", bosque.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVDSRS1DZ7HX5HPQCPC",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,make_scorer\n",
    "\n",
    "# Crear el modelo de Random Forest Regression\n",
    "bosque = RandomForestRegressor(n_estimators=100,\n",
    "                                criterion=\"squared_error\",  # Utilizar \"squared_error\" en lugar de \"mse\"\n",
    "                                max_features=\"sqrt\",\n",
    "                                bootstrap=True,\n",
    "                                oob_score=True,\n",
    "                                random_state=42)\n",
    "\n",
    "# Definir la m√©trica a utilizar (en este caso, negativo del Error Cuadr√°tico Medio para que sea coherente con la validaci√≥n cruzada)\n",
    "metrica = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Realizar validaci√≥n cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # Puedes ajustar el n√∫mero de divisiones (folds)\n",
    "resultados_cross_val = cross_val_score(bosque, X.values, y.values, cv=kf, scoring=metrica)\n",
    "\n",
    "# Imprimir los resultados de la validaci√≥n cruzada\n",
    "print(\"Resultados de la validaci√≥n cruzada:\")\n",
    "print(\"MSE por fold:\", resultados_cross_val)\n",
    "print(\"Promedio MSE:\", resultados_cross_val.mean())\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de datos\n",
    "bosque.fit(X.values, y.values)\n",
    "\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "# Predecir en un nuevo conjunto de datos\n",
    "nuevos_datos = X_test  # Usar X_test en lugar de una instancia individual\n",
    "predicciones = bosque.predict(nuevos_datos)\n",
    "print(\"Predicciones:\", predicciones)\n",
    "\n",
    "# Calcular las m√©tricas de evaluaci√≥n\n",
    "mae_rf = mean_absolute_error(y_test, predicciones)\n",
    "mse_rf = mean_squared_error(y_test, predicciones)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, predicciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVDGTMKC2342MCTCP77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Suponiendo que bosque es tu modelo entrenado\n",
    "for i, arbol in enumerate(bosque.estimators_[:3]):  # Limitar a los primeros tres √°rboles\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    tree.plot_tree(arbol, feature_names=X.columns.tolist(), filled=True, rounded=True)\n",
    "    plt.title(f\"√Årbol {i+1}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVD7RPA0MKF7695WM4T",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = bosque.predict(X_test)\n",
    "# Gr√°fico de dispersi√≥n de datos predichos vs. datos reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Predicciones')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='L√≠nea de Regresi√≥n Ideal')\n",
    "plt.title('Gr√°fico de Dispersi√≥n: Predicciones vs. Datos Reales')\n",
    "plt.xlabel('Datos Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVE7ZDKF3B4K18KG13P",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de entrenamiento\n",
    "y_train_pred = bosque.predict(X_train)\n",
    "\n",
    "# Gr√°fico de dispersi√≥n de datos predichos vs. datos reales (entrenamiento)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_train_pred, color='blue', label='Predicciones')\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--', label='L√≠nea de Regresi√≥n Ideal')\n",
    "plt.title('Gr√°fico de Dispersi√≥n: Predicciones vs. Datos Reales (Conjunto de Entrenamiento)')\n",
    "plt.xlabel('Datos Reales (Entrenamiento)')\n",
    "plt.ylabel('Predicciones (Entrenamiento)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVE82ZB9FNH1KH88H65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test):\n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular las m√©tricas de evaluaci√≥n\n",
    "    mae = metrics.mean_absolute_error(y_test, predicciones)\n",
    "    mse = metrics.mean_squared_error(y_test, predicciones)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_test, predicciones)\n",
    "    \n",
    "    return mae, mse, rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVFG0SYHSAYCA1QH8N4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo_lr = LinearRegression()\n",
    "mae_lr, mse_lr, rmse_lr, r2_lr = evaluar_modelo(modelo_lr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVFDJ4J9B7XBTTMB23Q",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "modelo_lasso = Lasso()\n",
    "mae_lasso, mse_lasso, rmse_lasso, r2_lasso = evaluar_modelo(modelo_lasso, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVGDKNA9FG2FKSMGMNM",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "modelo_svr = SVR()\n",
    "mae_svr, mse_svr, rmse_svr, r2_svr = evaluar_modelo(modelo_svr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVQD8G1HCPSVM7AVF1P",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "modelo_gb = GradientBoostingRegressor(random_state=42)\n",
    "mae_gb, mse_gb, rmse_gb, r2_gb = evaluar_modelo(modelo_gb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVRJ4HTR852VTFQ7GJV",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "modelo_svm = SVR()\n",
    "mae_svm, mse_svm, rmse_svm, r2_svm = evaluar_modelo(modelo_svm, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVR3R6PM0J258A8RRW7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "modelo_knn = KNeighborsRegressor()\n",
    "mae_knn, mse_knn, rmse_knn, r2_knn = evaluar_modelo(modelo_knn, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVTEJ6G0GDJH7BFK3YG",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "modelo_xgb = XGBRegressor(random_state=42)\n",
    "mae_xgb, mse_xgb, rmse_xgb, r2_xgb = evaluar_modelo(modelo_xgb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVTGFWFVQ8SMH2QVXRH",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression ya fue implementado en la regresi√≥n lineal\n",
    "mae_mlr, mse_mlr, rmse_mlr, r2_mlr = mae_lr, mse_lr, rmse_lr, r2_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVVB0ECMSTG66JJM380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "modelo_ridge = Ridge()\n",
    "mae_ridge, mse_ridge, rmse_ridge, r2_ridge = evaluar_modelo(modelo_ridge, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVV3BNDDN6TX4JSGYF0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "modelo_enr = ElasticNet()\n",
    "mae_enr, mse_enr, rmse_enr, r2_enr = evaluar_modelo(modelo_enr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVY2WM06XV6BVSF0ZCY",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "modelo_pnr = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "mae_pnr, mse_pnr, rmse_pnr, r2_pnr = evaluar_modelo(modelo_pnr, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVZHKQJ14Z8CWJ8F8EV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las m√©tricas de los modelos\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Regresi√≥n Lineal', 'Lasso Regression', 'Support Vector Regression', 'Gradient Boosting', 'SVM', 'KNN', 'XGBoost', 'Ridge Linear Regression', 'Elastic-Net Regression', 'Polynomial Regression'],\n",
    "    'MAE': [mae_lr, mae_lasso, mae_svr, mae_gb, mae_svm, mae_knn, mae_xgb, mae_ridge, mae_enr, mae_pnr],\n",
    "    'MSE': [mse_lr, mse_lasso, mse_svr, mse_gb, mse_svm, mse_knn, mse_xgb, mse_ridge, mse_enr, mse_pnr],\n",
    "    'RMSE': [rmse_lr, rmse_lasso, rmse_svr, rmse_gb, rmse_svm, rmse_knn, rmse_xgb, rmse_ridge, rmse_enr, rmse_pnr],\n",
    "    'R¬≤': [r2_lr, r2_lasso, r2_svr, r2_gb, r2_svm, r2_knn, r2_xgb, r2_ridge, r2_enr, r2_pnr],\n",
    "})\n",
    "\n",
    "# Agregar las m√©tricas del modelo de Random Forest a la tabla de resultados\n",
    "resultados.loc[len(resultados)] = ['Random Forest Regression', mae_rf, mse_rf, rmse_rf, r2_rf]\n",
    "\n",
    "# Mostrar el DataFrame con las m√©tricas\n",
    "print(resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZXCGDVZJ8DA84BBVW7J5TX3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los par√°metros para la b√∫squeda de hiperpar√°metros\n",
    "parametros = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "modelo_xgb_grid = XGBRegressor(random_state=42)\n",
    "busqueda = GridSearchCV(estimator=modelo_xgb_grid, param_grid=parametros, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entrenar el modelo con la b√∫squeda de hiperpar√°metros\n",
    "busqueda.fit(X_train, y_train)\n",
    "mejores_params = busqueda.best_params_\n",
    "\n",
    "# Evaluar el mejor modelo encontrado\n",
    "mejor_modelo_xgb = busqueda.best_estimator_\n",
    "mae_xgb_ht, mse_xgb_ht, rmse_xgb_ht, r2_xgb_ht = evaluar_modelo(mejor_modelo_xgb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# A√±adir el modelo hypertuned a la tabla de resultados\n",
    "resultados.loc[len(resultados)] = ['Hypertuned XGBoost', mae_xgb_ht, mse_xgb_ht, rmse_xgb_ht, r2_xgb_ht]\n",
    "\n",
    "# Mostrar el DataFrame actualizado con las m√©tricas\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; border: 1px solid #ddd; padding: 15px; border-radius: 10px;color: black\">\n",
    "    <p style=\"font-size: 18px; color: #2E86C1;\">An√°lisis de los Resultados de los Modelos</p>\n",
    "    <p>El an√°lisis de los resultados de los modelos proporciona una visi√≥n completa del rendimiento de cada modelo:</p>    \n",
    "    <ul>\n",
    "        <li>Mejor Modelo:</li>\n",
    "        <ul>\n",
    "            <li>Random Forest Regression: Este modelo tiene el rendimiento m√°s s√≥lido con un MAE bajo de aproximadamente 0.19, un MSE de alrededor de 0.06, un RMSE de aproximadamente 0.24 y un R¬≤ de alrededor de 0.74. Indica un bajo error y una buena capacidad para explicar la variabilidad de los datos.</li>\n",
    "        </ul>\n",
    "        <li>Segundos Mejores Modelos:</li>\n",
    "        <ul>\n",
    "            <li>Regresi√≥n Lineal: Aunque ligeramente superado por Random Forest, muestra un rendimiento s√≥lido con un MAE de aproximadamente 0.21, un MSE de alrededor de 0.07, un RMSE de aproximadamente 0.27 y un R¬≤ de alrededor de 0.68.</li>\n",
    "            <li>Polynomial Regression: Con un MAE de aproximadamente 0.25, un MSE de alrededor de 0.07, un RMSE de aproximadamente 0.26 y un R¬≤ de alrededor de 0.69, es otra opci√≥n s√≥lida.</li>\n",
    "        </ul>\n",
    "        <li>Peores Modelos:</li>\n",
    "        <ul>\n",
    "            <li>XGBoost: Muestra un rendimiento deficiente con un MAE de aproximadamente 0.76, un MSE de alrededor de 1.27, un RMSE de aproximadamente 1.13 y un R¬≤ negativo de alrededor de -4.79.</li>\n",
    "            <li>Hypertuned XGBoost: Similar al XGBoost regular, muestra un rendimiento muy pobre con un MAE de aproximadamente 0.75, un MSE de alrededor de 1.32, un RMSE de aproximadamente 1.15 y un R¬≤ negativo de alrededor de -5.03.</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    <p>En resumen, Random Forest Regression destaca como el mejor modelo, seguido de cerca por la Regresi√≥n Lineal y Polynomial Regression. XGBoost y su versi√≥n Hypertuned XGBoost muestran un rendimiento deficiente y deben ser evitados.</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
